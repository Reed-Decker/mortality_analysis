---
title: "Mortality Analysis"
author: "Reed Decker"
date: "2022-09-05"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(rstudioapi)
setwd(dirname(getActiveDocumentContext()$path))
renv::restore()
```

# Mortality Analysis

Recently in conversation, a relative mentioned anecdotal how heart complications seemed to be getting more and more treatable, and cited several examples of heart-attack victims she knew who had made successful recoveries from things that would have almost certainly been death sentences once. I thought this was interesting, but it made me wonder, how much better has medicine gotten at treating other illnesses? I've also heard a lot of women and minorities talk about their struggles with the healthcare system, so I thought it would also be illuminating to see how the trends in mortality differ by race and gender.

To start with, I went to the [CDC compressed mortality dataset](https://catalog.data.gov/dataset/cdc-wonder-mortality-underlying-cause-of-death) and queried the 1999-2016 database for death rates by International Classification of Disease (ICD) sub-chapter, year, age, race, and gender. I'm not actually interested in examining the data by age, but the CDC recommends looking at age adjusted death rates when comparing between population, so I need to age data to calculate that. 

## Data Cleaning

Unfortunately the CDC Wonder query system will not output queries that produce more than 75,000 results. In order to get all the data I wanted, I wound up having to submit a separate query for each age range, which means I now have 14 different datasets. To start, I'll need to load those in and merge them together. I'll also have a peek at the structure, dimensions, and the first few rows of the resulting dataframe.

```{r load_merge}
library(tidyverse)

# Load data by age

df_1     <- read.delim("mortality_1999-2016_1.txt")
df_1_4   <- read.delim("mortality_1999-2016_1-4.txt")
df_5_9   <- read.delim("mortality_1999-2016_5-9.txt")
df_10_14 <- read.delim("mortality_1999-2016_10-14.txt")
df_15_19 <- read.delim("mortality_1999-2016_15-19.txt")
df_20_24 <- read.delim("mortality_1999-2016_20-24.txt")
df_25_34 <- read.delim("mortality_1999-2016_25-34.txt")
df_35_44 <- read.delim("mortality_1999-2016_35-44.txt")
df_35_44 <- read.delim("mortality_1999-2016_35-44.txt")
df_45_54 <- read.delim("mortality_1999-2016_45-54.txt")
df_55_64 <- read.delim("mortality_1999-2016_55-64.txt")
df_65_74 <- read.delim("mortality_1999-2016_65-74.txt")
df_75_84 <- read.delim("mortality_1999-2016_75-84.txt")
df_85    <- read.delim("mortality_1999-2016_85+.txt")

# Merge into single dataframe

df <- rbind(df_1, 
            df_1_4, 
            df_5_9, 
            df_10_14, 
            df_15_19, 
            df_20_24, 
            df_25_34, 
            df_35_44,
            df_45_54,
            df_55_64,
            df_65_74,
            df_75_84,
            df_85)

dim(df)

str(df)
```

The only immediate issues I see are that several columns have redundant information, and some of them are the wrong data type as well. From the look of the first few rows, the only column that can't be simply converted to the proper data type is the Crude.Rate column. I'd like the crude death rate to be numeric, rather than character, but it looks like a lot of my death rates have been marked as "unreliable" which introduces a character string. Normally I'd want to remove those character strings or split them off into a different column. However, I'm actually going to want to calculate these rates myself. For example, if I'm making a figure where I split the data by race, but not gender, the crude rates given here won't work. However, the crude rate is calculated by the formula "(Deaths \* 100,000) / Population" so I have the information I need to obtain the crude rate for any section of the population I want, meaning I don't need this column. The fact that some of the rates are marked as unreliable isn't a concern in and of itself. While the CDC considers any crude rate calculated with less than 20 deaths to be unreliable, these aren't our final crude rates. Our actual crude rates will add together all the age groups after adjustment, meaning we should have more than enough deaths in each group to calculate a reliable estimate.

As far as the redundant columns go, for several fields, such as ICD subchapter, gender, and race, the query system automatically outputs both a plain English version of the data and a reference code. This means I have a lot of columns with perfectly correlated information. I'll deal with those in a moment, but before I do, I want to make sure I don't have any data cells marked as "NA" in the dataframe.

```{r check_NA}
apply(df, 2, function(x) sum(is.na(x)))
```

It looks like I have several NA values. The number of NA values in Year.Code, Year, Population, and Deaths are all the same, so it's a fair bet that it's the same rows containing NA values for each of them. There's also a couple in Age.Group.Code. I'll subset both groups of NA values and examine them to try and see what the cause is.

```{r na_subset}
age_group_na <- subset(df, subset = is.na(df$Age.Group.Code))
year_na <- subset(df, subset = is.na(df$Year))

knitr::kable(head(age_group_na))
knitr::kable(head(year_na))
```

It looks like the "Notes" column of each query I made contains information about the dataset and the query used to generate it. Every other column is either empty or NA for those rows. For some reason the Age.Group.Code column came back as NA for one query but blank for all the others, which is why it had only 60 NA values. This means I can simply remove all the NA values from the main dataframe, as they all contain no data.

```{r remove_empty_rows}
df <- subset(df, subset = !is.na(df$Year))
```

With the NA values taken care of, I also want to check to see if there are any other empty cells in the dataframe.

```{r check_empty}
apply(df, 2, function(x) sum(x == ""))
```

There are 137,664 empty cells in the Notes column. I know from earlier that the dataframe used to have 138,420 rows, and I just deleted 756, so our dataframe is currently 137,664 rows long. In other words, every cell in the Notes column is empty, so I can feel free to delete the entire column later on.

Now that the data appears to be fairly clean, I actually want to add a new column. For my analysis, I know that I'm going to want to look at ICD chapter at first, rather than sub-chapter, so I can narrow down areas of interest. Unfortunately, the queries I submited used all of the available fields to subset the data. In order to generate a column of ICD chapter codes, I'll have to extract that information from the subchapter codes.

Fortunately, the system used to create chapter and subchapter codes is simple. The individual cause of death codes are a letter and two digits ranging from A00 to Z99. The code for a chapter is simply a range of values (e.g. A00-B99). The code for a subchapter is the same, just with a narrower range (e.g. A00-A09, A16-A19, etc). I already have the subchapter ranges, so once I put in the chapter ranges, it should be easy to join them to the subchapters based on if the subchapter code falls inside the range of the chapter code.

To start, I want to define a new dataset that includes both the chapter codes and short versions of the titles for each chapter in the ICD 10. Fortunately the WHO maintains a [webpage with details on the ICD 10](https://icd.who.int/browse10/2016/en#/) I can use to get this information. Once I have the dataframe with the ICD chapter codes, I'm going to join the codes to the main dataframe. Most R functions for joining dataframes that I know of don't have the kind of inequality join I need to do this, so I'm going to load in the "sqldf" library to write an SQL join query instead.

```{r create_ICD_key}
# Make ICD Chapter and Chapter Code dataframe
icd_key <- data.frame(
  ICD.Chapter.Code = c(
    "A00-B99",
    "C00-D48",
    "D50-D89",
    "E00-E90",
    "F00-F99",
    "G00-G99",
    "H00-H59",
    "H60-H95",
    "I00-I99",
    "J00-J99",
    "K00-K93",
    "L00-L99",
    "M00-M99",
    "N00-N99",
    "O00-O99",
    "P00-P96",
    "Q00-Q99",
    "R00-R99",
    "S00-T98",
    "V01-Y98",
    "Z00-Z99",
    "U00-U99"
  ),
  ICD.Chapter = c(
    "Parasitic/Infectious Diseases",
    "Neoplams",
    "Blood Diseases",
    "Endocrine Diseases",
    "Mental Disorders",
    "Nervous System Diseases",
    "Eye Diseases",
    "Ear Diseases",
    "Circulatory Diseases",
    "Respiratory Diseases",
    "Digestive Diseases",
    "Skin Diseases",
    "Musculoskeletal Diseases",
    "Genitourinary Diseases",
    "Pregnancy/Childbirth",
    "Perinatal Conditions",
    "Congenital Malformations",
    "Not Classified Elsewhere",
    "Consequences of External Causes",
    "External Causes",
    "Healthcare Factors",
    "Special Purposes"
  )
)

# Join ICD Chapter Codes to dataframe

library(sqldf)

df <- sqldf("SELECT df.*, icd_key.'ICD.Chapter.Code' 
      FROM df 
      JOIN icd_key ON 
        LEFTSTR(df.'ICD.Sub.Chapter.Code', 3) >= 
          LEFTSTR(icd_key.'ICD.Chapter.Code', 3)
        AND LEFTSTR(df.'ICD.Sub.Chapter.Code', 3) <= 
            RIGHTSTR(icd_key.'ICD.Chapter.Code', 3)")
```

Next I want to make some changes to the data structure. I want the age group, gender, race, ICD chapter and ICD subchapter data to be factors, rather than character data. Before I make any conversions, I want to make sure there aren't any unexpected values in any of those columns that will wind up being coerced to NA if I try to convert to factor, or give me weird factor levels I didn't expect.

```{R check_unique_vectors}
unique(df$ICD.Chapter.Code)
unique(df$ICD.Sub.Chapter.Code)
unique(df$Age.Group)
unique(df$Age.Group.Code)
unique(df$Gender.Code)
unique(df$Race.Code)
```

It doesn't look like there's any nasty surprises hidden in the data, so I can go ahead and convert these values to factors.

```{r make_factor}

factors <- c("ICD.Chapter.Code",
             "ICD.Sub.Chapter.Code",
             "Age.Group.Code",
             "Gender.Code",
             "Race.Code")

df[,factors] <- lapply(df[,factors], factor)
```

I mentioned earlier I wanted to do something about all the redundant columns I have in the data. In general, I want to keep the ".Code" columns, because they contain much briefer versions of the data that are easier to use in code. However, when visualizing the data, I'll want more descriptive labels. Instead of deleting these columns outright, I'm going to set up a relational structure by making several new dataframes which match the code columns that I'm keeping in the dataframe to their plain English translations, just like the dataframe I programmed in for the ICD chapter codes. This way I can work with the main dataframe easily, but reference any information I need to make figures without too much trouble.

```{r make_vector_keys}
gender_key <- unique(df[, c("Gender.Code", "Gender")])
age_key <- unique(df[, c("Age.Group.Code", "Age.Group")])
icd_sub_key <- unique(df[, c("ICD.Chapter.Code", "ICD.Sub.Chapter.Code", "ICD.Sub.Chapter")])
race_key <- unique(df[, c("Race.Code", "Race")])

# Sort keys alphabetically where not already alphabetical

race_key <- arrange(race_key, Race.Code)
icd_key <- arrange(icd_key, ICD.Chapter.Code)
icd_sub_key <- arrange(icd_sub_key, ICD.Sub.Chapter.Code)
```

Now that I've made sure I have all the information about what each column means somewhere, I can go ahead and delete the redundant columns. Additionally, I noted earlier I wanted to remove the Notes and Crude.Rate columns. I'd also like the ICD.Chapter.Code column to appear as the first column, rather than the last, just for my own convenience. 

```{r remove_columns}
# Remove unwanted columns
df <- subset(df, select = -c(1, 2, 5, 6, 8, 10, 14))

# Put ICD.Chapter.Code first

df <- select(df, ICD.Chapter.Code, everything())
```

Now that my dataframe is clean and easy to work with, I can start having some fun with data!

## Exploritory Analysis

As I mentioned earlier, I want to look at age adjusted death rates, rather than just the crude death rate. The reason for this is that some causes of death are more frequent for certain age groups. For example, dementia is going to be a much more common cause of death for people in the older age groups. Differences between how many people are in each population can confound our findings as a result unless we account for those differences. The age adjusted mortality rate does this by converting each population into a standardized population. Currently the CDC uses the estimated population for the year 2000 as their standardized population. The estimates and the related age weights can be found [here](https://wonder.cdc.gov/wonder/help/cmf.html#2000%20Standard%20Population).

To calculate the age adjusted mortality rate itself is fairly simple. You multiply the crude death rate for each individual age group by the age weight, then add them together. When I queried the data, I could have actually had the age adjusted mortality rates included but, as with the crude rate, I want to define the groups of interest myself and calculate their specific age adjusted rates.

The first thing I want to do is add the age weights to the age group dataframe I made earlier.

```{r add_age_weights}
age_key$Age.Weight <- c(0.013818, # <1
                        0.055317, # 1-4
                        0.145565, # 5-9
                        0.145565, # 10-14
                        0.138646, # 15-19
                        0.138646, # 20-24
                        0.135573, # 25-34
                        0.162613, # 35-44
                        0.134834, # 45-54
                        0.087247, # 55-64
                        0.066037, # 65-74
                        0.044842, # 75-84
                        0.015508  # >=85
)
```

If I'm going to make a lot of different figures based on different groupings of people, I'm also going to want a way to easily and quickly calculate the age adjusted mortality rates by group, so I'm going to write a function that outputs just that. It should allow me to work out the age adjusted mortality rates for the populations I want in just a few commands and pipe the results into a figure.

```{r age_adjustment_function}

# Function takes the name of the dataframe, then the name(s) of any grouping variables of interest
age_adjust <- function(X, ...){
  
  # Age.Group.Call needs to be included alongside the specific groups listed in the function call.
  X <- group_by(X, ..., Age.Group.Code)
  
  X <- summarise(X, Population = sum(unique(Population)), Deaths = sum(Deaths))

  # Calculate crude rate for each age group
  X$Crude.Rate <- (X$Deaths * 100000) / X$Population
   
  # Add in the age weights from the age_key dataframe 
  X <- merge(
    X,
    age_key[, c("Age.Group.Code", "Age.Weight")],
    by = "Age.Group.Code"
  ) 
  
  # Multiply crude rates by age weight and sum across age groups for finished product
  X$Age.Adjustment <- X$Age.Weight * X$Crude.Rate
  
  X <- group_by(X, ...)
  
  X <- summarise(X, Crude.Rate.Adjusted = sum(Age.Adjustment))
  
  return(X)
}
```

### What are the leading causes of death from 1999 to 2016?

The first thing I want to know is what the top overall causes of death are. For this, I'm not going to use the age adjusted rates. I just want to get an idea of what the most common causes of death are, so all I want to do is sum the deaths by cause across the entire dataset. Because there are over a hundred subchapters in the ICD, I just want to look at ICD chapters at first to get a general picture.

```{r total_deaths_by_cause}
total_deaths <- df %>%
  left_join(icd_key, by = c("ICD.Chapter.Code" = "ICD.Chapter.Code")) %>%
  group_by(ICD.Chapter.Code, ICD.Chapter) %>%
  summarise(Deaths = sum(Deaths)) %>%
  arrange(desc(Deaths))

print(total_deaths)
```

Diseases of the circulatory system and neoplasms lead the other top causes of death by an order of magnitude. This isn't too surprising, as those are the chapters that include cancer and heart disease. Our least common causes of death include diseases of the eye, ears, deaths from codes reserved for special purposes, pregnancy and childbirth, and skin diseases. I'm actually quite surprised to see pregnancy and childbirth as low on the list as they are, given how dangerous childbirth has historically been.

This table also gives me some information on how I want to break down my figures. Looking at every ICD chapter by year would be too much information to show on a line graph and have it still be readable, so I already knew I'd want to split them across multiple figures. Now I also have some idea of which causes of death will fit on the same scale as one another.

### Have the leading causes of death changed?

This whole project was started by a discussion of how heart disease has become more treatable, so it only makes sense I take a look into that. I also want to graph it alongside neoplasms. I'm interested to see what the change in neoplasms looks like relative to the change in heart disease. Additionally, those two causes of death tower over all the others by a full order of magnitude, so I can't really put any other causes of death next to either of them and maintain a reasonable scale on the figure.

```{r cause_by_year}
death_cause <- c("C00-D48", "I00-I99")

filter(df, ICD.Chapter.Code %in% death_cause) %>%
  age_adjust(ICD.Chapter.Code, Year) %>%
  ggplot(aes(x = Year, y = Crude.Rate.Adjusted, color = ICD.Chapter.Code)) +
  geom_line() +
  geom_point() +
  ylab("Age Adjusted Crude Death Rate") +
  labs(title = "Top Causes of Death Over Time") +
  scale_color_discrete(
    labels = icd_key$ICD.Chapter[
      icd_key$ICD.Chapter.Code %in% death_cause
    ],
    name = "Cause of Death"
  )
```



There's an overall decline for both causes, but it's much steeper for circulatory diseases than neoplasms. The decline for neoplasms is impressively linear. I wouldn't normally expect to see such a steady and consistent decline in real-world data. By contrast the slope on the neoplasms appears less consistent. Just eyeballing it, I'd say it's probably linear, but there are some potential hints of a logarithmic curve to it. I don't think I have data across enough years to get meaningful results out of trying to fit both functions to the data and seeing which performs better, but it might be worth seeing if I can equate some of the older data, which uses older versions of the ICD, to get a larger sample size in another analysis.

### Is the decline in leading causes of death the same across gender and race?

Earlier I'd mentioned race as a potential factor, so it may be interesting to split these results by race to see if there are any major differences.

```{r lead_death_by_gender}

labels_top <- c("Neoplasms", "Circulatory Diseases")
names(labels_top) <- death_cause

filter(df, ICD.Chapter.Code %in% death_cause) %>%
  age_adjust(ICD.Chapter.Code, Year, Race.Code) %>%
  ggplot(aes(x = Year, y = Crude.Rate.Adjusted, color = Race.Code)) +
  geom_line() +
  geom_point() +
  facet_wrap(~ICD.Chapter.Code, labeller = labeller(ICD.Chapter.Code = labels_top))+
  ylab("Age Adjusted Crude Death Rate") +
  labs(title = "Top Causes of Death Over Time") +
  scale_color_discrete(labels = race_key$Race, name = "Race")
```

Overall there are differences in death rate based on race, but they're largely the same across time. Where there are declines in death by a certain cause, they seem to affect each race category in a more or less similar way. When split by race, the 

```{r lead_death_by_race}

death_cause <- c("I00-I99", "C00-D48")

filter(df, ICD.Chapter.Code %in% death_cause) %>%
  age_adjust(ICD.Chapter.Code, Year, Race.Code) %>%
  ggplot(
    aes(
      x = Year,
      y = Crude.Rate.Adjusted,
      shape = ICD.Chapter.Code,
      color = Race.Code
    )
  ) +
  geom_line() +
  geom_point() +
  ylab("Age Adjusted Crude Death Rate") +
  labs(title = "Top Causes of Death Over Time") +
  scale_shape_discrete(
    labels = icd_key$ICD.Chapter[
      icd_key$ICD.Chapter.Code %in% death_cause
    ],
    name = "Cause of Death"
  ) +
  scale_color_discrete(labels = race_key$Race, name = "Race")
```

Unsurprisingly, given white people tend to have better access to health care, they also have the lowest death rates for both ICD codes. What's more interesting, however, is how the difference in rate between neoplasms and circulatory diseases changes between races. For white people, the death rate from circulatory disease has fallen over the years to the point where it's no longer dramatically higher. For people in the Asian or Pacific Islander categories, however, the death rate for circulatory diseases is still massively greater than for neoplasms, even in 2016. The actual slopes for each race look about the same, however, so it doesn't seem like changes in medicine over this time period disproportionately affected white people more than other races, but at the same time the factors causing non-white people to have higher overall death rates don't seem to have been improved either.

### Have common causes of death changed over time?

```{r common_cause_by_year}
death_cause <- total_deaths$ICD.Chapter.Code[
  which(
    total_deaths$Deaths > 999999 & 
      total_deaths$Deaths < 10000000
  )
]

filter(df, ICD.Chapter.Code %in% death_cause) %>%
  age_adjust(ICD.Chapter.Code, Year) %>%
  ggplot(aes(x = Year, y = Crude.Rate.Adjusted, color = ICD.Chapter.Code)) +
  geom_line() +
  geom_point(aes(shape = ICD.Chapter.Code)) + 
  ylab("Age Adjusted Crude Death Rate") +
  labs(title = "Common Causes of Death Over Time") +
  scale_color_discrete(
    labels = icd_key$ICD.Chapter[
      icd_key$ICD.Chapter.Code %in% death_cause
    ],
    name = "Cause of Death"
  ) +
  scale_linetype_discrete(
    labels = icd_key$ICD.Chapter[
      icd_key$ICD.Chapter.Code %in% death_cause
    ],
    name = "Cause of Death"
  ) +
  scale_shape_manual(
    labels = icd_key$ICD.Chapter[
      icd_key$ICD.Chapter.Code %in% death_cause
    ],
    name = "Cause of Death",
    values = c(15, 16, 17, 15, 16, 17, 15, 16)
  )
```

Most of these death rates are fairly steady over time, but deaths due to nervous system diseases and mental disorders show a general trend of increasing, and there's a spike in deaths by external causes around 2014-2015. Coming from a psychology background, I'm most interested here in the deaths from mental disorders, which suddenly start to decline around 2013. Again, I think I'd be useful to break this down by race and gender to see if the trend is coming from any particular segment of the population.

#### Do deaths by mental disorder differ by race and gender?

```{r mental_disorder_breakdown}
filter(df, ICD.Chapter.Code == "F01-F99") %>%
  age_adjust(ICD.Chapter.Code, Year, Race.Code, Gender.Code) %>%
  ggplot(aes(x = Year, y = Crude.Rate.Adjusted, color = Race.Code, shape = Gender.Code)) +
  geom_line() +
  geom_point() +
  ylab("Age Adjusted Crude Death Rate") +
  labs(title = "Deaths from Mental Disorder by Race and Gender") +
  scale_color_discrete(labels = race_key$Race, name = "Race") +
  scale_shape_discrete(labels = gender_key$Gender, name = "Gender")
```

As it happens, there are a lot of interesting elements in this figure. In general women are more likely to report suffering from mental illness than men, but in terms of death from mental disorder, it looks like men who are Asian or Pacific Islanders have higher death rates from mental illness than women. The same is true for American Indians and Alaska Natives. For Black or African American people, the death rate from mental illness for men and women is about the same until 2005, where the death rate for women starts to rise more rapidly than for men. Around 2010 we see something similar for white people, where the death rate for women grows over that of men for a time. This increase is most notable for white people, but the death rate for women from mental illness seems to increases, compared to the male death rate, for all races around this time. However, death from mental disease is a fairly broad category. I suspect that answers to exactly what is going on here might be clearer if we looked at the individual causes of death. I don't have those as part of the present dataset, but I can query that data for another analysis.

Finally I want to look into that external cause of death spike we saw.

#### Do deaths by external causes differ by race and gender?

```{r external_cause_breakdown}
filter(df, ICD.Chapter.Code == "V01-Y89") %>%
  age_adjust(ICD.Chapter.Code, Year, Race.Code, Gender.Code) %>%
  ggplot(aes(x = Year, y = Crude.Rate.Adjusted, color = Race.Code, shape = Gender.Code)) +
  geom_line() +
  geom_point() +
  ylab("Age Adjusted Crude Death Rate") +
  labs(title = "Deaths from External Causes by Race and Gender") +
  scale_color_discrete(labels = race_key$Race, name = "Race") +
  scale_shape_discrete(labels = gender_key$Gender, name = "Gender")
```

From this figure we can see that the spike in deaths from external causes is almost entirely accounted for by non-white men. Non-white men not only have higher death rates from external causes overall, but the sudden increase from around 2014 doesn't happen for women, or white men. Again, it's hard to say exactly why this happens from the data we have, but a clear trend is visible.

## Summary

From this dataset, it's clear to see that, in spite of improvements in medicine over the past 20 odd years, there is still a fair deal of racial and gender-based inequality when it comes to causes of mortality. We also do see increases in death rates for certain kinds of death. However, it should be noted that every dies of something eventually. A decrease in deaths from neoplasms and heart disease might lead to an increase in death by mental disorder, as people who previously would have died from heart attack of cancer find themselves living long enough to die of dementia or other age-related causes that fall under the umbrella of mental disease.

While I wasn't able to get detailed information about these trends from the current dataset, I've also narrowed down questions for further examination. It would be more convienient to have all the causes of death in this dataset, rather than having to query for more information. However, the CDC portal only allows for 75,000 results at a time, so using a general dataset to narrow down more specific questions to query is worth the effort, as it saves the time of having to send and merge a massive number of queries to obtain information on all individual causes of death for all races and genders in every age group across all years.
